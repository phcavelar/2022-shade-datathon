{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import nibabel as nib\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(filepath=None, img_data=None, **kwargs):\n",
    "    if filepath is not None:\n",
    "        nii_img = nib.load(os.path.expanduser(filepath))\n",
    "        nii_data = nii_img.get_fdata()\n",
    "    elif img_data is not None:\n",
    "        nii_data = img_data\n",
    "    else:\n",
    "        raise ValueError(\"Either filepath or img_data must be not None\")\n",
    "\n",
    "    plt.ioff()\n",
    "    fig = plt.figure()\n",
    "    plt.ion()\n",
    "    im = plt.imshow(nii_data[...,0], vmin=nii_data.min(), vmax=nii_data.max(), **kwargs)\n",
    "\n",
    "    out = widgets.Output()\n",
    "    @out.capture()\n",
    "    def update(change):\n",
    "        with out:\n",
    "            if change['name'] == 'value':\n",
    "                im.set_data(nii_data[...,change['new']])\n",
    "                fig.canvas.draw_idle\n",
    "        \n",
    "    slider = widgets.IntSlider(value=0, min=0, max=nii_data.shape[-1]-1)\n",
    "    slider.observe(update)\n",
    "    display(widgets.VBox([slider, fig.canvas]))\n",
    "    display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_images(filepaths, **kwargs):\n",
    "    images_data = []\n",
    "    depth = None\n",
    "    for fpath in filepaths:\n",
    "        nii_img = nib.load(os.path.expanduser(fpath))\n",
    "        images_data.append(nii_img.get_fdata())\n",
    "        if depth is None:\n",
    "            depth = images_data[-1].shape\n",
    "        else:\n",
    "            assert depth == images_data[-1].shape, \"All images must have the same shape!\"\n",
    "\n",
    "    plt.ioff()\n",
    "    fig, axes = plt.subplots(1,len(filepaths))\n",
    "    plt.ion()\n",
    "\n",
    "    ims = []\n",
    "    for i in range(len(filepaths)):\n",
    "        ims.append(axes[i].imshow(images_data[i][...,0], vmin=images_data[i].min(), vmax=images_data[i].max(), **kwargs))\n",
    "    out = widgets.Output()\n",
    "    @out.capture()\n",
    "    def update(change):\n",
    "        with out:\n",
    "            if change['name'] == 'value':\n",
    "                for i in range(len(filepaths)):\n",
    "                    ims[i].set_data(images_data[i][...,change['new']])\n",
    "                fig.canvas.draw_idle\n",
    "        \n",
    "    slider = widgets.IntSlider(value=0, min=0, max=depth[-1]-1)\n",
    "    slider.observe(update)\n",
    "    display(widgets.VBox([slider, fig.canvas]))\n",
    "    display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.expanduser(os.path.expandvars(\"~/data/medicaldecathlon/Task10_Colon\"))\n",
    "train_dataset_img_path = os.path.join(dataset_path,\"imagesTr\")\n",
    "test_dataset_img_path = os.path.join(dataset_path,\"imagesTs\")\n",
    "train_dataset_label_path = os.path.join(dataset_path,\"labelsTr\")\n",
    "train_dataset_frailty_path = os.path.join(dataset_path,\"train_clean.csv\")\n",
    "test_dataset_frailty_path = os.path.join(dataset_path,\"test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_filenames = sorted(filter(lambda s: not s.startswith(\".\"), os.listdir(os.path.join(train_dataset_img_path))))\n",
    "test_image_filenames = sorted(filter(lambda s: not s.startswith(\".\"), os.listdir(os.path.join(test_dataset_img_path))))\n",
    "train_label_filenames = sorted(filter(lambda s: not s.startswith(\".\"), os.listdir(os.path.join(train_dataset_label_path))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_filenames[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 20\n",
    "\n",
    "plot_multiple_images([\n",
    "    os.path.join(train_dataset_img_path, train_image_filenames[img_idx],),\n",
    "    os.path.join(train_dataset_label_path, train_label_filenames[img_idx],),\n",
    "], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nib.load(os.path.join(train_dataset_label_path, train_label_filenames[0])).get_fdata()\n",
    "df = pd.DataFrame(\n",
    "    dict(zip((\"x\",\"y\",\"z\"),np.where(b!=0)))\n",
    ")\n",
    "df[[\"x\",\"y\"]].hist(sharex=True, sharey=True, bins=max(b.shape), range=(0,max(b.shape)), density=True,)\n",
    "df[[\"z\"]].hist(bins=b.shape[2], range=(0,b.shape[2]), density=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(train_dataset_frailty_path, index_col=\"PatientID\")\n",
    "\n",
    "df_labels.loc[df_labels[\"Risk Category\"]==\"LOW\",\"Risk Category\"] = 0\n",
    "df_labels.loc[df_labels[\"Risk Category\"]==\"MEDIUM\",\"Risk Category\"] = 1\n",
    "df_labels.loc[df_labels[\"Risk Category\"]==\"HIGH\",\"Risk Category\"] = 2\n",
    "df_labels = df_labels.astype(int)\n",
    "\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.hist(density=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.value_counts([\"Risk Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_test = pd.read_csv(test_dataset_frailty_path, index_col=\"PatientID\")\n",
    "\n",
    "df_labels_test.loc[df_labels_test[\"Risk Category\"]==\"LOW\",\"Risk Category\"] = 0\n",
    "df_labels_test.loc[df_labels_test[\"Risk Category\"]==\"MEDIUM\",\"Risk Category\"] = 1\n",
    "df_labels_test.loc[df_labels_test[\"Risk Category\"]==\"HIGH\",\"Risk Category\"] = 2\n",
    "df_labels_test = df_labels_test.astype(int)\n",
    "\n",
    "df_labels_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels[[\"Risk Category\"]].hist(density=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_values = {\n",
    "    \"idx\":[],\n",
    "    \"min\":[],\n",
    "    \"p25\":[],\n",
    "    \"p50\":[],\n",
    "    \"p75\":[],\n",
    "    \"max\":[],\n",
    "    \"mass\":[],\n",
    "    \"vol\":[],\n",
    "    \"density\":[],\n",
    "}\n",
    "\n",
    "for img_idx in range(len(train_image_filenames)):\n",
    "    img_path = os.path.join(train_dataset_img_path, train_image_filenames[img_idx])\n",
    "    seg_path = os.path.join(train_dataset_label_path, train_label_filenames[img_idx])\n",
    "\n",
    "    img = nib.load(os.path.expanduser(img_path)).get_fdata()\n",
    "    seg = nib.load(os.path.expanduser(seg_path)).get_fdata()\n",
    "    assert(np.max(seg) in [0,1]), \"AAA\"\n",
    "    seg = seg.astype(np.bool)\n",
    "\n",
    "    seg_mass = np.sum(img[seg])\n",
    "    seg_vol = np.sum(seg)\n",
    "    seg_density = seg_mass/seg_vol\n",
    "    print(f\"{img_idx} {os.path.basename(img_path)}\\tdensity {seg_density:.3f} = mass {seg_mass:.3f} / vol {seg_vol:.3f}\")\n",
    "    for key, value in zip(\n",
    "        img_values.keys(),\n",
    "        [img_idx, np.quantile(img, 0.0), np.quantile(img, 0.25), np.quantile(img, 0.50), np.quantile(img, 0.75), np.quantile(img, 1.00), seg_mass, seg_vol, seg_density]\n",
    "    ):\n",
    "        img_values[key].append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(img_values).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eval_dir in map(lambda d: os.path.expanduser(os.path.expandvars(os.path.join(\"~/data/shade2022/validation_cleaned\",d))), [\"covid/images\", \"kidney/images\"]):\n",
    "    img_paths = []\n",
    "    for data_handle in [f for f in os.listdir(eval_dir) if not f.startswith(\".DS_Store\")]:\n",
    "        data_dir = os.path.join(eval_dir, data_handle)\n",
    "        img_paths.append(os.path.join(data_dir, [f for f in os.listdir(data_dir) if not f.startswith(\".DS_Store\")][0]))\n",
    "        scan = nib.load(img_paths[-1]).get_fdata()\n",
    "        print(img.min(), img.max(), img_paths[-1])\n",
    "        scan_mod = np.clip(scan, a_min=-120, a_max=240)\n",
    "        plot_image(\n",
    "            img_data=scan_mod,\n",
    "            cmap=\"gray\")\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('shade2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f16b433f0ec686bf0f85bf779465d9d7469a0980a4c6364e7aadd876bd30562"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
