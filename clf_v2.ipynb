{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D classification example based on DenseNet\n",
    "\n",
    "This tutorial shows an example of 3D classification task based on DenseNet and array format transforms.\n",
    "\n",
    "Here, the task is given to classify MR images into male/female.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/3d_classification/torch/densenet_training_array.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "import datetime\n",
    "import socket\n",
    "import functools\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "import monai\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, ImageDataset\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    Compose,\n",
    "    RandRotate90,\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "\n",
    "pin_memory = torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark = False #torch.cuda.is_available() # Set this to true if the code fails\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_values(model, loader):\n",
    "    t_model_outputs = []\n",
    "    t_test_labels = []\n",
    "    for test_data in loader:\n",
    "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(test_images)\n",
    "            val_outputs_argmax = val_outputs.argmax(dim=1)\n",
    "            t_model_outputs.append(val_outputs_argmax.cpu().detach().numpy())\n",
    "            t_test_labels.append(test_labels.cpu().detach().numpy())\n",
    "    conf_model_outputs = np.concatenate(t_model_outputs)\n",
    "    conf_test_labels = np.concatenate(t_test_labels)\n",
    "    return conf_model_outputs, conf_test_labels\n",
    "\n",
    "def get_cm(conf_model_outputs, conf_test_labels, num_classes):\n",
    "    conf_matrix = np.zeros((num_classes,num_classes))\n",
    "    for i in range(num_classes):\n",
    "        in_class_i = conf_test_labels==i\n",
    "        for j in range(num_classes):\n",
    "            in_class_i_predicted_in_class_j = sum(conf_model_outputs[in_class_i]==j)\n",
    "            conf_matrix[i,j] = in_class_i_predicted_in_class_j\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "#directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "#root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "root_dir = os.path.expanduser(os.path.expandvars(\"~/data/medicaldecathlon/\"))\n",
    "data_dir = os.path.join(root_dir, \"Task10_Colon\")\n",
    "train_dataset_frailty_path = os.path.join(data_dir,\"train_v2_clean.csv\")\n",
    "test_dataset_frailty_path = os.path.join(data_dir,\"test_v2_clean.csv\")\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
    "train_images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTs\", \"*.nii.gz\")))\n",
    "test_image_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(train_dataset_frailty_path, index_col=\"PatientID\").dropna()\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_test = pd.read_csv(test_dataset_frailty_path, index_col=\"PatientID\").dropna()\n",
    "df_labels_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.loc[df_labels[\"Risk Category\"]==\"LOW\",\"Risk Category\"] = 0\n",
    "df_labels.loc[df_labels[\"Risk Category\"]==\"MEDIUM\",\"Risk Category\"] = 0\n",
    "df_labels.loc[df_labels[\"Risk Category\"]==\"HIGH\",\"Risk Category\"] = 1\n",
    "\n",
    "df_labels_test.loc[df_labels_test[\"Risk Category\"]==\"LOW\",\"Risk Category\"] = 0\n",
    "df_labels_test.loc[df_labels_test[\"Risk Category\"]==\"MEDIUM\",\"Risk Category\"] = 0\n",
    "df_labels_test.loc[df_labels_test[\"Risk Category\"]==\"HIGH\",\"Risk Category\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_filepath(fpath):\n",
    "    return int(os.path.basename(fpath).split(\"_\")[1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SLICES = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": df_labels.loc[patient_id,\"Risk Category\"]}\n",
    "    for image_name,patient_id in zip(train_images,map(get_id_from_filepath,train_images))\n",
    "    if patient_id in df_labels.index and nib.load(image_name).get_fdata().shape[2]>=MIN_SLICES\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dicts = [\n",
    "    {\"image\": image_name, \"label\": df_labels_test.loc[patient_id,\"Risk Category\"]}\n",
    "    for image_name,patient_id in zip(test_image_paths,map(get_id_from_filepath,test_image_paths))\n",
    "    if patient_id in df_labels_test.index and nib.load(image_name).get_fdata().shape[2]>=MIN_SLICES\n",
    "]\n",
    "len(test_data_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IXI dataset as a demo, downloadable from https://brain-development.org/ixi-dataset/\n",
    "images = np.array([d[\"image\"] for d in data_dicts])\n",
    "# 2 binary labels for gender classification: man or woman\n",
    "labels = np.array([d[\"label\"] for d in data_dicts])\n",
    "\n",
    "test_images = [d[\"image\"] for d in test_data_dicts]\n",
    "# 2 binary labels for gender classification: man or woman\n",
    "test_labels = [d[\"label\"] for d in test_data_dicts]\n",
    "\n",
    "\n",
    "# Represent labels in one-hot format for binary classifier training,\n",
    "# BCEWithLogitsLoss requires target to have same shape as input\n",
    "#labels = torch.nn.functional.one_hot(torch.as_tensor(labels)).float()\n",
    "num_labels = int(max(labels))+1\n",
    "num_labels, labels[:5], test_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [nib.load(datapoint[\"image\"]).get_fdata().shape for datapoint in data_dicts]\n",
    "np_shapes = np.stack(shapes)\n",
    "minshapes = np.min(np_shapes, axis=0)\n",
    "minshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_crop = 96\n",
    "for newcrop in range(original_crop,2,-1):\n",
    "    if newcrop <= min(minshapes):\n",
    "        crop_shapes = tuple([newcrop]*3)\n",
    "        break\n",
    "crop_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pct = 0.2\n",
    "val_split = int(val_pct*len(labels))\n",
    "possible_labels = sorted(list(set(labels)))\n",
    "proportion_in_labels = np.array([sum(labels==i)/len(labels) for i in possible_labels])\n",
    "val_per_labels = [int(l*val_split) for l in proportion_in_labels]\n",
    "proportion_in_labels, val_per_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_weigths = 1/proportion_in_labels[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = np.concatenate([np.random.choice([i for i, l in enumerate(labels) if l==p], c, replace=False) for p,c in zip(possible_labels, val_per_labels)])\n",
    "in_val = np.isin(np.arange(len(labels)),val_idx)\n",
    "in_train = ~in_val\n",
    "train_idx = np.arange(len(labels))[in_train]\n",
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4#3\n",
    "while (len(images)-val_split)%batch_size==1 or val_split%batch_size==1:\n",
    "    batch_size +=1\n",
    "    print(\"Changing batch size so that no batch has size 1\")\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "train_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), Resize(crop_shapes), RandRotate90()])\n",
    "\n",
    "val_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), Resize(crop_shapes)])\n",
    "\n",
    "# Define nifti dataset, data loader\n",
    "check_ds = ImageDataset(image_files=images, labels=labels, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=3, num_workers=2, pin_memory=pin_memory)\n",
    "\n",
    "im, label = monai.utils.misc.first(check_loader)\n",
    "print(type(im), im.shape, label, label.shape)\n",
    "\n",
    "# create a training data loader\n",
    "train_ds = ImageDataset(image_files=images[train_idx].tolist(), labels=labels[train_idx].tolist(), transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=pin_memory)\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = ImageDataset(image_files=images[val_idx].tolist(), labels=labels[val_idx].tolist(), transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=2, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_fns = {\n",
    "    s.__name__.split(\"_score\")[0]: s for s in [f1_score, accuracy_score, balanced_accuracy_score]\n",
    "}\n",
    "val_metric = \"balanced_accuracy\"\n",
    "metrics_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "model = monai.networks.nets.DenseNet(spatial_dims=3, in_channels=1, out_channels=num_labels).to(device)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(torch.tensor(1/proportion_in_labels, device=device, dtype=torch.float32))\n",
    "# loss_function = torch.nn.BCEWithLogitsLoss()  # also works with this data\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "\n",
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "writer = SummaryWriter(f\"v2_runs/{datetime.datetime.now():%Y-%m-%d_%H:%M:%S}_{socket.gethostname()}\")\n",
    "max_epochs = 256\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    try:\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            b_inputs, b_labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(b_inputs)\n",
    "            loss = loss_function(outputs, b_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "\n",
    "            num_correct = 0.0\n",
    "            metric_count = 0\n",
    "            v_pred, v_label = get_predicted_values(model, val_loader)\n",
    "            cm_counts = get_cm(v_pred, v_label, num_labels)\n",
    "\n",
    "            all_metrics = {\n",
    "                metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "            }\n",
    "            metric = all_metrics[val_metric]\n",
    "            metric_values.append(metric)\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"v2_best_metric_model_classification3d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "\n",
    "            print(f\"Current epoch: {epoch+1} current {val_metric}: {metric:.4f} \")\n",
    "            print(f\"Best {val_metric}: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "            for metric in all_metrics:\n",
    "                writer.add_scalar(f\"val_{metric}\", all_metrics[metric], epoch + 1)\n",
    "            cm_pct = cm_counts/cm_counts.sum(axis=1,keepdims=True)\n",
    "            print(cm_pct)\n",
    "            for i in range(num_labels):\n",
    "                for j in range(num_labels):\n",
    "                    writer.add_scalar(f\"count l{i}_p{j}\",cm_counts[i,j], epoch + 1)\n",
    "                    writer.add_scalar(f\"pct l{i}_p{j}\",cm_pct[i,j], epoch + 1)\n",
    "    except KeyboardInterrupt: \n",
    "        break\n",
    "\n",
    "print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occlusion sensitivity\n",
    "One method for trying to visualise why the network made a given prediction is occlusion sensitivity. We occlude part of the image, and see how the probability of a given prediction changes. We then iterate over the image, moving the occluded portion as we go, and in doing so we build up a sensitivity map detailing which areas were the most important in making the decision.\n",
    "\n",
    "#### Bounds\n",
    "If we were to test the occlusion centred on all voxels in our image, we would have to do `torch.prod(im.shape) = 96^3 = ~1e6` predictions. We can use the bounding box to only to the estimations in a region of interest, for example over one slice.\n",
    "\n",
    "To do this, we simply give the bounding box as `(minC,maxC,minD,maxD,minH,maxH,minW,maxW)`. We can use `-1` for any value to use its full extent (`0` and `im.shape-1` for min's and max's, respectively).\n",
    "\n",
    "#### Output\n",
    "The output image in this example will look fairly bad, since our network hasn't been trained for very long. Training for longer should improve the quality of the occlusion map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a validation data loader\n",
    "test_ds = ImageDataset(image_files=test_images, labels=test_labels, transform=val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, train_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, val_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, test_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_loader = DataLoader(test_ds, batch_size=1, num_workers=2, pin_memory=pin_memory)\n",
    "itera = iter(occ_loader)\n",
    "\n",
    "\n",
    "def get_next_im():\n",
    "    test_data = next(itera)\n",
    "    return test_data[0].to(device), test_data[1].unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "def plot_occlusion_heatmap(im, heatmap):\n",
    "    plt.subplots(1, 2)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.squeeze(im.cpu()))\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(heatmap)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random image and its corresponding label\n",
    "img, label = get_next_im()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the occlusion sensitivity map\n",
    "occ_sens = monai.visualize.OcclusionSensitivity(nn_module=model, mask_size=12, n_batch=10, stride=12)\n",
    "# Only get a single slice to save time.\n",
    "# For the other dimensions (channel, width, height), use\n",
    "# -1 to use 0 and img.shape[x]-1 for min and max, respectively\n",
    "depth_slice = img.shape[2] // 2\n",
    "occ_sens_b_box = [depth_slice-1, depth_slice, -1, -1, -1, -1]\n",
    "\n",
    "occ_result, _ = occ_sens(x=img, b_box=occ_sens_b_box)\n",
    "occ_result = occ_result[0, label.argmax().item()][None]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25, 15), facecolor=\"white\")\n",
    "\n",
    "for i, im in enumerate([img[:, :, depth_slice, ...], occ_result]):\n",
    "    cmap = \"gray\" if i == 0 else \"jet\"\n",
    "    ax = axes[i]\n",
    "    im_show = ax.imshow(np.squeeze(im[0][0].detach().cpu()), cmap=cmap)\n",
    "    ax.axis(\"off\")\n",
    "    fig.colorbar(im_show, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('shade2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f16b433f0ec686bf0f85bf779465d9d7469a0980a4c6364e7aadd876bd30562"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
