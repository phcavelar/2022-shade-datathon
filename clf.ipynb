{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D classification based on DenseNet\n",
    "\n",
    "Based on a tutorial by the MONAI Consortium: https://github.com/Project-MONAI/tutorials/blob/main/3d_classification/densenet_training_array.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "import datetime\n",
    "import socket\n",
    "import functools\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import pydicom\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "import monai\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, ImageDataset\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirst,\n",
    "    Compose,\n",
    "    RandRotate90,\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "\n",
    "pin_memory = torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark = False #torch.cuda.is_available() # Set this to true if the code fails\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print_config()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to get predictions/confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_values(model, loader):\n",
    "    # Iterates through a dataloader and gets the prediction and labels\n",
    "    t_model_outputs = []\n",
    "    t_test_labels = []\n",
    "    for test_data in loader:\n",
    "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(test_images)\n",
    "            val_outputs_argmax = val_outputs.argmax(dim=1)\n",
    "            t_model_outputs.append(val_outputs_argmax.cpu().detach().numpy())\n",
    "            t_test_labels.append(test_labels.cpu().detach().numpy())\n",
    "    conf_model_outputs = np.concatenate(t_model_outputs)\n",
    "    conf_test_labels = np.concatenate(t_test_labels)\n",
    "    return conf_model_outputs, conf_test_labels\n",
    "\n",
    "def get_cm(conf_model_outputs, conf_test_labels, num_classes):\n",
    "    # Get a (count) confusion matrix based on the predictions and true labels\n",
    "    conf_matrix = np.zeros((num_classes,num_classes))\n",
    "    for i in range(num_classes):\n",
    "        in_class_i = conf_test_labels==i\n",
    "        for j in range(num_classes):\n",
    "            in_class_i_predicted_in_class_j = sum(conf_model_outputs[in_class_i]==j)\n",
    "            conf_matrix[i,j] = in_class_i_predicted_in_class_j\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code expects the data to be inside a directory in the user's home directory. Data is from the [medical decathlon](http://medicaldecathlon.com/) and can be downloaded from https://drive.google.com/drive/folders/1HqEgzS8BV2c7xYNrZdEAnrHk7osJJ--2?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.expanduser(os.path.expandvars(\"~/data/medicaldecathlon/\"))\n",
    "data_dir = os.path.join(root_dir, \"Task10_Colon\")\n",
    "train_dataset_frailty_path = os.path.join(data_dir,\"train_clean.csv\")\n",
    "test_dataset_frailty_path = os.path.join(data_dir,\"test_clean.csv\")\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
    "train_images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTs\", \"*.nii.gz\")))\n",
    "test_image_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training and testing labels. You should move these from this repo's `data` folder to the same folder as that contain the image folders above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(train_dataset_frailty_path, index_col=\"PatientID\").dropna()\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_test = pd.read_csv(test_dataset_frailty_path, index_col=\"PatientID\").dropna()\n",
    "df_labels_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change values in the dataframes from string to class ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.loc[df_labels[\"Risk Category\"]==\"LOW\",\"Risk Category\"] = 0\n",
    "df_labels.loc[df_labels[\"Risk Category\"]==\"MEDIUM\",\"Risk Category\"] = 1\n",
    "df_labels.loc[df_labels[\"Risk Category\"]==\"HIGH\",\"Risk Category\"] = 2\n",
    "\n",
    "df_labels_test.loc[df_labels_test[\"Risk Category\"]==\"LOW\",\"Risk Category\"] = 0\n",
    "df_labels_test.loc[df_labels_test[\"Risk Category\"]==\"MEDIUM\",\"Risk Category\"] = 1\n",
    "df_labels_test.loc[df_labels_test[\"Risk Category\"]==\"HIGH\",\"Risk Category\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_filepath(fpath):\n",
    "    # Gets patient ID from its filepath\n",
    "    return int(os.path.basename(fpath).split(\"_\")[1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any patients whose scans have less than this number of slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SLICES = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get image and label information on a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": df_labels.loc[patient_id,\"Risk Category\"]}\n",
    "    for image_name,patient_id in zip(train_images,map(get_id_from_filepath,train_images))\n",
    "    if patient_id in df_labels.index and nib.load(image_name).get_fdata().shape[2]>=MIN_SLICES\n",
    "]\n",
    "len(data_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dicts = [\n",
    "    {\"image\": image_name, \"label\": df_labels_test.loc[patient_id,\"Risk Category\"]}\n",
    "    for image_name,patient_id in zip(test_image_paths,map(get_id_from_filepath,test_image_paths))\n",
    "    if patient_id in df_labels_test.index and nib.load(image_name).get_fdata().shape[2]>=MIN_SLICES\n",
    "]\n",
    "len(test_data_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate image and labels into their own lists, get the number of labels we have (number of classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array([d[\"image\"] for d in data_dicts])\n",
    "labels = np.array([d[\"label\"] for d in data_dicts])\n",
    "\n",
    "test_images = [d[\"image\"] for d in test_data_dicts]\n",
    "test_labels = [d[\"label\"] for d in test_data_dicts]\n",
    "\n",
    "# Number of different classes we have in the dataset\n",
    "num_labels = int(max(labels))+1\n",
    "num_labels, labels[:5], test_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the minimum shape of the scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [nib.load(datapoint[\"image\"]).get_fdata().shape for datapoint in data_dicts]\n",
    "np_shapes = np.stack(shapes)\n",
    "minshapes = np.min(np_shapes, axis=0)\n",
    "minshapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original code cropped images to a 96x96x96 image, since a significant amount of our images don't have that size, we need to adjust the crop to fit our training images' size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_crop = 96\n",
    "for newcrop in range(original_crop,2,-1):\n",
    "    if newcrop <= min(minshapes):\n",
    "        crop_shapes = tuple([newcrop]*3)\n",
    "        break\n",
    "crop_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the validation with `val_pct` images being allocated to the validation dataset with a stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pct = 0.1\n",
    "val_split = int(val_pct*len(labels))\n",
    "possible_labels = sorted(list(set(labels)))\n",
    "proportion_in_labels = np.array([sum(labels==i)/len(labels) for i in possible_labels])\n",
    "val_per_labels = [int(l*val_split) for l in proportion_in_labels]\n",
    "proportion_in_labels, val_per_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into validation/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = np.concatenate([np.random.choice([i for i, l in enumerate(labels) if l==p], c, replace=False) for p,c in zip(possible_labels, val_per_labels)])\n",
    "in_val = np.isin(np.arange(len(labels)),val_idx)\n",
    "in_train = ~in_val\n",
    "train_idx = np.arange(len(labels))[in_train]\n",
    "val_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick fix to make sure training doesn't crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "while (len(images)-val_split)%batch_size==1 or val_split%batch_size==1:\n",
    "    batch_size +=1\n",
    "    print(\"Changing batch size so that no batch has size 1, as single-instance batches cause an error\")\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and validation transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "train_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), Resize(crop_shapes), RandRotate90()])\n",
    "\n",
    "val_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(), Resize(crop_shapes)])\n",
    "\n",
    "# Define nifti dataset, data loader\n",
    "check_ds = ImageDataset(image_files=images, labels=labels, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=3, num_workers=2, pin_memory=pin_memory)\n",
    "\n",
    "im, label = monai.utils.misc.first(check_loader)\n",
    "print(type(im), im.shape, label, label.shape)\n",
    "\n",
    "# create a training data loader\n",
    "train_ds = ImageDataset(image_files=images[train_idx].tolist(), labels=labels[train_idx].tolist(), transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=pin_memory)\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = ImageDataset(image_files=images[val_idx].tolist(), labels=labels[val_idx].tolist(), transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=2, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define metrics to follow-up the training as well as validation metric to save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_fns = {\n",
    "    (s.func.__name__ if isinstance(s, functools.partial) else s.__name__).split(\"_score\")[0]: s\n",
    "    for s in [functools.partial(f1_score, average=\"weighted\"), accuracy_score, balanced_accuracy_score]\n",
    "}\n",
    "val_metric = \"accuracy\"\n",
    "metrics_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "model = monai.networks.nets.DenseNet(spatial_dims=3, in_channels=1, out_channels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()#torch.tensor(1/proportion_in_labels, device=device, dtype=torch.float32)\n",
    "# loss_function = torch.nn.BCEWithLogitsLoss()  # also works with this data\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "\n",
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "writer = SummaryWriter(f\"runs{num_labels}/{datetime.datetime.now():%Y-%m-%d_%H:%M:%S}_{socket.gethostname()}\")\n",
    "max_epochs = 256\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    try:\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            b_inputs, b_labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(b_inputs)\n",
    "            loss = loss_function(outputs, b_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "\n",
    "            num_correct = 0.0\n",
    "            metric_count = 0\n",
    "            v_pred, v_label = get_predicted_values(model, val_loader)\n",
    "            cm_counts = get_cm(v_pred, v_label, num_labels)\n",
    "\n",
    "            all_metrics = {\n",
    "                metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "            }\n",
    "            metric = all_metrics[val_metric]\n",
    "            metric_values.append(metric)\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), f\"best_metric_model{num_labels}_classification3d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "\n",
    "            print(f\"Current epoch: {epoch+1} current {val_metric}: {metric:.4f} \")\n",
    "            print(f\"Best {val_metric}: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "            for metric in all_metrics:\n",
    "                writer.add_scalar(f\"val_{metric}\", all_metrics[metric], epoch + 1)\n",
    "            cm_pct = cm_counts/cm_counts.sum(axis=1,keepdims=True)\n",
    "            print(cm_pct)\n",
    "            for i in range(num_labels):\n",
    "                for j in range(num_labels):\n",
    "                    writer.add_scalar(f\"count l{i}_p{j}\",cm_counts[i,j], epoch + 1)\n",
    "                    writer.add_scalar(f\"pct l{i}_p{j}\",cm_pct[i,j], epoch + 1)\n",
    "            torch.save(model.state_dict(), f\"epoch{epoch}_model{num_labels}_classification3d_array.pth\")\n",
    "    except KeyboardInterrupt: \n",
    "        break\n",
    "\n",
    "print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "torch.save(model.state_dict(), \"last_model{num_labels}_classification3d_array.pth\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model results\n",
    "\n",
    "Here we test the model on the training/valid/test datasets, get their confusion matrices and their metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a validation data loader\n",
    "test_ds = ImageDataset(image_files=test_images, labels=test_labels, transform=val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=2, num_workers=2, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"last_model{num_labels}_classification3d_array.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, train_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, val_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, test_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"best_metric_model{num_labels}_classification3d_array.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, train_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, val_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, test_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"epoch{26}_model{num_labels}_classification3d_array.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, train_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, val_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_label, v_pred = get_predicted_values(model, test_loader)\n",
    "conf_matrix = get_cm(v_label, v_pred, num_labels)\n",
    "all_metrics = {\n",
    "    metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "}\n",
    "conf_matrix, all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full training\n",
    "\n",
    "Train the model on all images for external use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_images = np.concatenate([images, test_images])\n",
    "full_labels = np.concatenate([labels, test_labels])\n",
    "\n",
    "full_images.shape, full_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pct = 0.1\n",
    "val_split = int(val_pct*len(full_labels))\n",
    "possible_labels = sorted(list(set(full_labels)))\n",
    "proportion_in_labels = np.array([sum(labels==i)/len(labels) for i in possible_labels])\n",
    "val_per_labels = [int(l*val_split) for l in proportion_in_labels]\n",
    "proportion_in_labels, val_per_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_weigths = 1/proportion_in_labels[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = np.concatenate([np.random.choice([i for i, l in enumerate(labels) if l==p], c, replace=False) for p,c in zip(possible_labels, val_per_labels)])\n",
    "in_val = np.isin(np.arange(len(labels)),val_idx)\n",
    "in_train = ~in_val\n",
    "train_idx = np.arange(len(labels))[in_train]\n",
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4#3\n",
    "while (len(full_images)-val_split)%batch_size==1 or val_split%batch_size==1:\n",
    "    batch_size +=1\n",
    "    print(\"Changing batch size so that no batch has size 1\")\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "train_ds = ImageDataset(image_files=full_images[train_idx].tolist(), labels=full_labels[train_idx].tolist(), transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=pin_memory)\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = ImageDataset(image_files=full_images[val_idx].tolist(), labels=full_labels[val_idx].tolist(), transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=2, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "model = monai.networks.nets.DenseNet(spatial_dims=3, in_channels=1, out_channels=num_labels).to(device)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(torch.tensor(1/proportion_in_labels, device=device, dtype=torch.float32))\n",
    "# loss_function = torch.nn.BCEWithLogitsLoss()  # also works with this data\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "\n",
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "writer = SummaryWriter(f\"full_runs/{datetime.datetime.now():%Y-%m-%d_%H:%M:%S}_{socket.gethostname()}\")\n",
    "max_epochs = 256\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    try:\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            b_inputs, b_labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(b_inputs)\n",
    "            loss = loss_function(outputs, b_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "\n",
    "            num_correct = 0.0\n",
    "            metric_count = 0\n",
    "            v_pred, v_label = get_predicted_values(model, val_loader)\n",
    "            cm_counts = get_cm(v_pred, v_label, num_labels)\n",
    "\n",
    "            all_metrics = {\n",
    "                metric: metrics_fns[metric](v_label, v_pred) for metric in metrics_fns\n",
    "            }\n",
    "            metric = all_metrics[val_metric]\n",
    "            metric_values.append(metric)\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"full_best_metric_model_classification3d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "\n",
    "            print(f\"Current epoch: {epoch+1} current {val_metric}: {metric:.4f} \")\n",
    "            print(f\"Best {val_metric}: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "            for metric in all_metrics:\n",
    "                writer.add_scalar(f\"val_{metric}\", all_metrics[metric], epoch + 1)\n",
    "            cm_pct = cm_counts/cm_counts.sum(axis=1,keepdims=True)\n",
    "            print(cm_pct)\n",
    "            for i in range(num_labels):\n",
    "                for j in range(num_labels):\n",
    "                    writer.add_scalar(f\"count l{i}_p{j}\",cm_counts[i,j], epoch + 1)\n",
    "                    writer.add_scalar(f\"pct l{i}_p{j}\",cm_pct[i,j], epoch + 1)\n",
    "    except KeyboardInterrupt: \n",
    "        break\n",
    "\n",
    "print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "torch.save(model.state_dict(), \"full_last_model_classification3d_array.pth\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = os.path.expanduser(os.path.expandvars(os.path.join(\"~/data/shade2022/validation_cleaned\",\"covid/images\")))\n",
    "eval_img_paths = []\n",
    "for data_handle in [f for f in os.listdir(eval_dir) if not f.startswith(\".DS_Store\")]:\n",
    "    data_dir = os.path.join(eval_dir, data_handle)\n",
    "    eval_img_paths.append(os.path.join(data_dir, [f for f in os.listdir(data_dir) if not f.startswith(\".DS_Store\")][0]))\n",
    "\n",
    "# create a validation data loader\n",
    "eval_ds = ImageDataset(image_files=np.array(eval_img_paths), labels=np.array([0]*len(eval_img_paths)), transform=val_transforms)\n",
    "eval_loader = DataLoader(eval_ds, batch_size=2, num_workers=2, pin_memory=pin_memory)\n",
    "\n",
    "v_label, v_pred = get_predicted_values(model, train_loader)\n",
    "print(*list(zip(map(lambda p: p.split(\"/\")[-2], eval_img_paths), v_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = os.path.expanduser(os.path.expandvars(os.path.join(\"~/data/shade2022/validation_cleaned\",\"kidney/images\")))\n",
    "eval_img_paths = []\n",
    "for data_handle in [f for f in os.listdir(eval_dir) if not f.startswith(\".DS_Store\")]:\n",
    "    data_dir = os.path.join(eval_dir, data_handle)\n",
    "    eval_img_paths.append(os.path.join(data_dir, [f for f in os.listdir(data_dir) if not f.startswith(\".DS_Store\")][0]))\n",
    "\n",
    "# create a validation data loader\n",
    "eval_ds = ImageDataset(image_files=np.array(eval_img_paths), labels=np.array([0]*len(eval_img_paths)), transform=val_transforms)\n",
    "eval_loader = DataLoader(eval_ds, batch_size=2, num_workers=2, pin_memory=pin_memory)\n",
    "\n",
    "v_label, v_pred = get_predicted_values(model, train_loader)\n",
    "print(*list(zip(map(lambda p: p.split(\"/\")[-2], eval_img_paths), v_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('shade2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f16b433f0ec686bf0f85bf779465d9d7469a0980a4c6364e7aadd876bd30562"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
